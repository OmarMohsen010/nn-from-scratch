{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76107a74",
   "metadata": {},
   "source": [
    "# PyTarsh Neural Network Library - Project Demo\n",
    "\n",
    "## Team Members\n",
    "- Omar Mohsen\n",
    "- Youssf Mostafa\n",
    "- Ahmed Abdallah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28961b77",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### 1.1 Library Overview\n",
    "PyTarsh is a neural network library built from scratch using only NumPy. This library was developed to understand the fundamental concepts of deep learning by implementing core components without relying on high-level frameworks like TensorFlow or PyTorch.\n",
    "\n",
    "### 1.2 Key Features\n",
    "Our library includes the following components:\n",
    "\n",
    "**Layers:**\n",
    "- Dense (Fully Connected) Layer\n",
    "\n",
    "**Activation Functions:**\n",
    "- ReLU (Rectified Linear Unit)\n",
    "- Sigmoid\n",
    "- Tanh (Hyperbolic Tangent)\n",
    "- Softmax\n",
    "- Linear (Identity)\n",
    "\n",
    "**Loss Functions:**\n",
    "- Mean Squared Error (MSE)\n",
    "\n",
    "**Optimizers:**\n",
    "- Stochastic Gradient Descent (SGD)\n",
    "\n",
    "**Model Architecture:**\n",
    "- Sequential Model (layers stacked in sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5d006",
   "metadata": {},
   "source": [
    "### 1.3 Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95167d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import PyTarsh components\n",
    "import sys\n",
    "sys.path.append('..')  # Go up one directory\n",
    "from PyTarsh import Sequential, Dense, SGD\n",
    "from PyTarsh import mse_loss, mse_gradient\n",
    "from PyTarsh import ReLU, Sigmoid, Tanh, Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226dcd4",
   "metadata": {},
   "source": [
    "## 2. Gradient Checking (Unit Testing)\n",
    "\n",
    "### 2.1 What is Gradient Checking?\n",
    "\n",
    "Gradient checking is a technique used to verify that our backpropagation implementation is correct. It compares the analytical gradients computed by backpropagation with numerical gradients computed using finite differences.\n",
    "\n",
    "**Formula for Numerical Gradient:**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W} \\approx \\frac{L(W + \\epsilon) - L(W - \\epsilon)}{2\\epsilon}$$\n",
    "\n",
    "Where:\n",
    "- $L$ is the loss function\n",
    "- $W$ is a weight parameter\n",
    "- $\\epsilon$ is a small value (typically $10^{-7}$)\n",
    "\n",
    "If our backpropagation is implemented correctly, the analytical gradient should be nearly identical to the numerical gradient (difference < $10^{-5}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e6d4c",
   "metadata": {},
   "source": [
    "### 2.2 Gradient Checking Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a5d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(model, X, Y, epsilon=1e-7, loss_fn=mse_loss):\n",
    "    \"\"\"\n",
    "    Perform gradient checking to verify backpropagation implementation.\n",
    "    \n",
    "    Compares analytical gradients (from backprop) with numerical gradients\n",
    "    computed using finite differences: [L(W + ε) - L(W - ε)] / (2ε)\n",
    "    \n",
    "    Args:\n",
    "        model: Sequential model with trained layers\n",
    "        X: Input data, shape (batch_size, input_dim)\n",
    "        Y: Target data, shape (batch_size, output_dim)\n",
    "        epsilon: Small value for numerical gradient approximation (default: 1e-7)\n",
    "        loss_fn: Loss function to use (default: mse_loss)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing gradient differences for each layer\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"GRADIENT CHECKING\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Epsilon: {epsilon}\")\n",
    "    print(f\"Dataset size: {X.shape}\")\n",
    "    print()\n",
    "    \n",
    "    # Step 1: Forward pass and compute analytical gradients\n",
    "    predictions = model.forward(X)\n",
    "    loss = loss_fn(predictions, Y)\n",
    "    loss_grad = mse_gradient(predictions, Y)\n",
    "    model.backward(loss_grad)\n",
    "    \n",
    "    print(f\"Initial Loss: {loss:.8f}\")\n",
    "    print()\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Step 2: Check gradients for each layer\n",
    "    for layer_idx, layer in enumerate(model.layers):\n",
    "        if not hasattr(layer, 'weights'):\n",
    "            continue\n",
    "            \n",
    "        print(f\"Layer {layer_idx}: {layer.__class__.__name__}\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        # Get analytical gradients\n",
    "        analytical_weight_grad = layer.weights_gradient.copy()\n",
    "        analytical_bias_grad = layer.biases_gradient.copy()\n",
    "        \n",
    "        # Initialize numerical gradients\n",
    "        numerical_weight_grad = np.zeros_like(layer.weights)\n",
    "        numerical_bias_grad = np.zeros_like(layer.biases)\n",
    "        \n",
    "        # Check WEIGHT gradients using numerical approximation\n",
    "        print(\"Checking weight gradients...\")\n",
    "        original_weights = layer.weights.copy()\n",
    "        \n",
    "        # Sample a few random weights to check (checking all can be slow)\n",
    "        num_samples = min(10, layer.weights.size)\n",
    "        indices = np.random.choice(layer.weights.size, num_samples, replace=False)\n",
    "        \n",
    "        for idx in indices:\n",
    "            i, j = np.unravel_index(idx, layer.weights.shape)\n",
    "            \n",
    "            # Compute L(W + ε)\n",
    "            layer.weights[i, j] = original_weights[i, j] + epsilon\n",
    "            predictions_plus = model.forward(X)\n",
    "            loss_plus = loss_fn(predictions_plus, Y)\n",
    "            \n",
    "            # Compute L(W - ε)\n",
    "            layer.weights[i, j] = original_weights[i, j] - epsilon\n",
    "            predictions_minus = model.forward(X)\n",
    "            loss_minus = loss_fn(predictions_minus, Y)\n",
    "            \n",
    "            # Numerical gradient: [L(W + ε) - L(W - ε)] / (2ε)\n",
    "            numerical_weight_grad[i, j] = (loss_plus - loss_minus) / (2 * epsilon)\n",
    "            \n",
    "            # Restore original weight\n",
    "            layer.weights[i, j] = original_weights[i, j]\n",
    "        \n",
    "        # Check BIAS gradients using numerical approximation\n",
    "        print(\"Checking bias gradients...\")\n",
    "        original_biases = layer.biases.copy()\n",
    "        \n",
    "        for j in range(layer.biases.shape[1]):\n",
    "            # Compute L(b + ε)\n",
    "            layer.biases[0, j] = original_biases[0, j] + epsilon\n",
    "            predictions_plus = model.forward(X)\n",
    "            loss_plus = loss_fn(predictions_plus, Y)\n",
    "            \n",
    "            # Compute L(b - ε)\n",
    "            layer.biases[0, j] = original_biases[0, j] - epsilon\n",
    "            predictions_minus = model.forward(X)\n",
    "            loss_minus = loss_fn(predictions_minus, Y)\n",
    "            \n",
    "            # Numerical gradient: [L(b + ε) - L(b - ε)] / (2ε)\n",
    "            numerical_bias_grad[0, j] = (loss_plus - loss_minus) / (2 * epsilon)\n",
    "            \n",
    "            # Restore original bias\n",
    "            layer.biases[0, j] = original_biases[0, j]\n",
    "        \n",
    "        # Compare analytical vs numerical gradients\n",
    "        # Extract only the sampled weights for comparison\n",
    "        sampled_analytical = np.array([analytical_weight_grad.flat[idx] for idx in indices])\n",
    "        sampled_numerical = np.array([numerical_weight_grad.flat[idx] for idx in indices])\n",
    "        \n",
    "        weight_diff = np.abs(sampled_analytical - sampled_numerical)\n",
    "        bias_diff = np.abs(analytical_bias_grad - numerical_bias_grad)\n",
    "        \n",
    "        # Compute relative error: |analytical - numerical| / max(|analytical|, |numerical|)\n",
    "        weight_relative_error = weight_diff / (np.maximum(np.abs(sampled_analytical), np.abs(sampled_numerical)) + 1e-8)\n",
    "        bias_relative_error = bias_diff / (np.maximum(np.abs(analytical_bias_grad), np.abs(numerical_bias_grad)) + 1e-8)\n",
    "        \n",
    "        # Store results\n",
    "        results[f'layer_{layer_idx}'] = {\n",
    "            'weight_max_diff': np.max(weight_diff),\n",
    "            'weight_mean_diff': np.mean(weight_diff),\n",
    "            'weight_relative_error': np.mean(weight_relative_error),\n",
    "            'bias_max_diff': np.max(bias_diff),\n",
    "            'bias_mean_diff': np.mean(bias_diff),\n",
    "            'bias_relative_error': np.mean(bias_relative_error)\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nWeight Gradients (sampled {num_samples} values):\")\n",
    "        print(f\"  Max absolute difference: {np.max(weight_diff):.2e}\")\n",
    "        print(f\"  Mean absolute difference: {np.mean(weight_diff):.2e}\")\n",
    "        print(f\"  Mean relative error: {np.mean(weight_relative_error):.2e}\")\n",
    "        \n",
    "        print(f\"\\nBias Gradients:\")\n",
    "        print(f\"  Max absolute difference: {np.max(bias_diff):.2e}\")\n",
    "        print(f\"  Mean absolute difference: {np.mean(bias_diff):.2e}\")\n",
    "        print(f\"  Mean relative error: {np.mean(bias_relative_error):.2e}\")\n",
    "        \n",
    "        # Determine if gradients are correct\n",
    "        weight_ok = np.max(weight_diff) < 1e-5\n",
    "        bias_ok = np.max(bias_diff) < 1e-5\n",
    "        \n",
    "        if weight_ok and bias_ok:\n",
    "            print(f\"\\n✓ PASSED: Gradients are correct!\")\n",
    "        else:\n",
    "            print(f\"\\n✗ FAILED: Gradients may be incorrect!\")\n",
    "            if not weight_ok:\n",
    "                print(f\"  - Weight gradient difference too large\")\n",
    "            if not bias_ok:\n",
    "                print(f\"  - Bias gradient difference too large\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"GRADIENT CHECKING COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d669b2",
   "metadata": {},
   "source": [
    "### 2.3 Running Gradient Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "244fcf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_gradient_check_example():\n",
    "    \"\"\"\n",
    "    Simple example demonstrating gradient checking on XOR problem\n",
    "    \"\"\"\n",
    "    print(\"\\nGradient Checking Example: XOR Problem\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create XOR dataset\n",
    "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=float)\n",
    "    Y = np.array([[0], [1], [1], [0]], dtype=float)\n",
    "    \n",
    "    # Create a simple network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2, 4, activation=\"tanh\"))\n",
    "    model.add(Dense(4, 1, activation=\"sigmoid\"))\n",
    "    \n",
    "    # Perform gradient checking\n",
    "    results = gradient_check(model, X, Y, epsilon=1e-7)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be945d40",
   "metadata": {},
   "source": [
    "### 2.4 Gradient Checking Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f738c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Checking Example: XOR Problem\n",
      "======================================================================\n",
      "======================================================================\n",
      "GRADIENT CHECKING\n",
      "======================================================================\n",
      "Epsilon: 1e-07\n",
      "Dataset size: (4, 2)\n",
      "\n",
      "Initial Loss: 0.27478910\n",
      "\n",
      "Layer 0: Dense\n",
      "----------------------------------------------------------------------\n",
      "Checking weight gradients...\n",
      "Checking bias gradients...\n",
      "\n",
      "Weight Gradients (sampled 8 values):\n",
      "  Max absolute difference: 3.23e-10\n",
      "  Mean absolute difference: 1.56e-10\n",
      "  Mean relative error: 7.59e-08\n",
      "\n",
      "Bias Gradients:\n",
      "  Max absolute difference: 2.51e-10\n",
      "  Mean absolute difference: 1.35e-10\n",
      "  Mean relative error: 1.16e-08\n",
      "\n",
      "✓ PASSED: Gradients are correct!\n",
      "\n",
      "Layer 1: Dense\n",
      "----------------------------------------------------------------------\n",
      "Checking weight gradients...\n",
      "Checking bias gradients...\n",
      "\n",
      "Weight Gradients (sampled 4 values):\n",
      "  Max absolute difference: 5.14e-10\n",
      "  Mean absolute difference: 2.95e-10\n",
      "  Mean relative error: 1.76e-08\n",
      "\n",
      "Bias Gradients:\n",
      "  Max absolute difference: 2.70e-10\n",
      "  Mean absolute difference: 2.70e-10\n",
      "  Mean relative error: 4.09e-09\n",
      "\n",
      "✓ PASSED: Gradients are correct!\n",
      "\n",
      "======================================================================\n",
      "GRADIENT CHECKING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Interpretation:\n",
      "----------------------------------------------------------------------\n",
      "If max absolute difference < 1e-5: ✓ Backpropagation is CORRECT\n",
      "If max absolute difference > 1e-5: ✗ Backpropagation may be INCORRECT\n",
      "\n",
      "Typical good values:\n",
      "  - Absolute difference: < 1e-7 (excellent), < 1e-5 (good)\n",
      "  - Relative error: < 1e-5 (excellent), < 1e-3 (acceptable)\n"
     ]
    }
   ],
   "source": [
    "results = simple_gradient_check_example()\n",
    "    \n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"-\"*70)\n",
    "print(\"If max absolute difference < 1e-5: ✓ Backpropagation is CORRECT\")\n",
    "print(\"If max absolute difference > 1e-5: ✗ Backpropagation may be INCORRECT\")\n",
    "print()\n",
    "print(\"Typical good values:\")\n",
    "print(\"  - Absolute difference: < 1e-7 (excellent), < 1e-5 (good)\")\n",
    "print(\"  - Relative error: < 1e-5 (excellent), < 1e-3 (acceptable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06981455",
   "metadata": {},
   "source": [
    "### 2.5 Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a9f67",
   "metadata": {},
   "source": [
    "**Pass Criteria:**\n",
    "- ✓ Max absolute difference < $10^{-5}$: Backpropagation is **CORRECT**\n",
    "- ✗ Max absolute difference > $10^{-5}$: Backpropagation may be **INCORRECT**\n",
    "\n",
    "**Typical Good Values:**\n",
    "- Absolute difference: < $10^{-7}$ (excellent), < $10^{-5}$ (good)\n",
    "- Relative error: < $10^{-5}$ (excellent), < $10^{-3}$ (acceptable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc54d56",
   "metadata": {},
   "source": [
    "## 3. XOR Problem\n",
    "\n",
    "### 3.1 Problem Description\n",
    "\n",
    "The XOR (Exclusive OR) problem is a classic non-linear classification problem that cannot be solved by a single perceptron. It requires a neural network with at least one hidden layer.\n",
    "\n",
    "**XOR Truth Table:**\n",
    "\n",
    "| Input 1 | Input 2 | Output |\n",
    "|---------|---------|--------|\n",
    "| 0       | 0       | 0      |\n",
    "| 0       | 1       | 1      |\n",
    "| 1       | 0       | 1      |\n",
    "| 1       | 1       | 0      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3a11ad",
   "metadata": {},
   "source": [
    "### 3.2 Dataset Preparation\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253d9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XOR dataset\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=float)\n",
    "Y = np.array([[0], [1], [1], [0]], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e348f4",
   "metadata": {},
   "source": [
    "### 3.3 Network Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b755acd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Architecture:\n",
      "======================================================================\n",
      "Network Architecture\n",
      "======================================================================\n",
      "Layer 1: Dense + tanh\n",
      "  Shape: (2, 4)\n",
      "  Parameters: 12\n",
      "----------------------------------------------------------------------\n",
      "Layer 2: Dense + tanh\n",
      "  Shape: (4, 2)\n",
      "  Parameters: 10\n",
      "----------------------------------------------------------------------\n",
      "Layer 3: Dense + sigmoid\n",
      "  Shape: (2, 1)\n",
      "  Parameters: 3\n",
      "----------------------------------------------------------------------\n",
      "Total Parameters: 25\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 4 units\n",
    "model.add(Dense(2,4,activation=\"tanh\"))\n",
    "\n",
    "# Add the second hidden layer with 2 units\n",
    "model.add(Dense(4,2,activation=\"tanh\"))\n",
    "\n",
    "# Add the output layer with only 1 unit\n",
    "model.add(Dense(2,1,activation=\"sigmoid\"))\n",
    "\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'weights'):\n",
    "        layer.weights = np.random.randn(*layer.weights.shape)\n",
    "\n",
    "print(\"Network Architecture:\")\n",
    "model.summary()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d740b7c",
   "metadata": {},
   "source": [
    "### 3.4 Training the Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee56110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/10000, Loss: 0.221620\n",
      "Epoch 200/10000, Loss: 0.182071\n",
      "Epoch 300/10000, Loss: 0.157287\n",
      "Epoch 400/10000, Loss: 0.145231\n",
      "Epoch 500/10000, Loss: 0.139000\n",
      "Epoch 600/10000, Loss: 0.135355\n",
      "Epoch 700/10000, Loss: 0.132974\n",
      "Epoch 800/10000, Loss: 0.131251\n",
      "Epoch 900/10000, Loss: 0.129841\n",
      "Epoch 1000/10000, Loss: 0.128418\n",
      "Epoch 1100/10000, Loss: 0.126221\n",
      "Epoch 1200/10000, Loss: 0.117874\n",
      "Epoch 1300/10000, Loss: 0.069395\n",
      "Epoch 1400/10000, Loss: 0.034316\n",
      "Epoch 1500/10000, Loss: 0.020714\n",
      "Epoch 1600/10000, Loss: 0.014102\n",
      "Epoch 1700/10000, Loss: 0.010403\n",
      "Epoch 1800/10000, Loss: 0.008111\n",
      "Epoch 1900/10000, Loss: 0.006581\n",
      "Epoch 2000/10000, Loss: 0.005500\n",
      "Epoch 2100/10000, Loss: 0.004702\n",
      "Epoch 2200/10000, Loss: 0.004093\n",
      "Epoch 2300/10000, Loss: 0.003615\n",
      "Epoch 2400/10000, Loss: 0.003231\n",
      "Epoch 2500/10000, Loss: 0.002916\n",
      "Epoch 2600/10000, Loss: 0.002654\n",
      "Epoch 2700/10000, Loss: 0.002433\n",
      "Epoch 2800/10000, Loss: 0.002244\n",
      "Epoch 2900/10000, Loss: 0.002081\n",
      "Epoch 3000/10000, Loss: 0.001939\n",
      "Epoch 3100/10000, Loss: 0.001815\n",
      "Epoch 3200/10000, Loss: 0.001704\n",
      "Epoch 3300/10000, Loss: 0.001606\n",
      "Epoch 3400/10000, Loss: 0.001518\n",
      "Epoch 3500/10000, Loss: 0.001439\n",
      "Epoch 3600/10000, Loss: 0.001368\n",
      "Epoch 3700/10000, Loss: 0.001303\n",
      "Epoch 3800/10000, Loss: 0.001243\n",
      "Epoch 3900/10000, Loss: 0.001189\n",
      "Epoch 4000/10000, Loss: 0.001139\n",
      "Epoch 4100/10000, Loss: 0.001093\n",
      "Epoch 4200/10000, Loss: 0.001050\n",
      "Epoch 4300/10000, Loss: 0.001011\n",
      "Epoch 4400/10000, Loss: 0.000974\n",
      "Epoch 4500/10000, Loss: 0.000940\n",
      "Epoch 4600/10000, Loss: 0.000908\n",
      "Epoch 4700/10000, Loss: 0.000878\n",
      "Epoch 4800/10000, Loss: 0.000850\n",
      "Epoch 4900/10000, Loss: 0.000823\n",
      "Epoch 5000/10000, Loss: 0.000798\n",
      "Epoch 5100/10000, Loss: 0.000775\n",
      "Epoch 5200/10000, Loss: 0.000753\n",
      "Epoch 5300/10000, Loss: 0.000732\n",
      "Epoch 5400/10000, Loss: 0.000712\n",
      "Epoch 5500/10000, Loss: 0.000693\n",
      "Epoch 5600/10000, Loss: 0.000675\n",
      "Epoch 5700/10000, Loss: 0.000658\n",
      "Epoch 5800/10000, Loss: 0.000642\n",
      "Epoch 5900/10000, Loss: 0.000627\n",
      "Epoch 6000/10000, Loss: 0.000612\n",
      "Epoch 6100/10000, Loss: 0.000598\n",
      "Epoch 6200/10000, Loss: 0.000585\n",
      "Epoch 6300/10000, Loss: 0.000572\n",
      "Epoch 6400/10000, Loss: 0.000559\n",
      "Epoch 6500/10000, Loss: 0.000548\n",
      "Epoch 6600/10000, Loss: 0.000536\n",
      "Epoch 6700/10000, Loss: 0.000525\n",
      "Epoch 6800/10000, Loss: 0.000515\n",
      "Epoch 6900/10000, Loss: 0.000505\n",
      "Epoch 7000/10000, Loss: 0.000495\n",
      "Epoch 7100/10000, Loss: 0.000486\n",
      "Epoch 7200/10000, Loss: 0.000477\n",
      "Epoch 7300/10000, Loss: 0.000468\n",
      "Epoch 7400/10000, Loss: 0.000460\n",
      "Epoch 7500/10000, Loss: 0.000452\n",
      "Epoch 7600/10000, Loss: 0.000444\n",
      "Epoch 7700/10000, Loss: 0.000436\n",
      "Epoch 7800/10000, Loss: 0.000429\n",
      "Epoch 7900/10000, Loss: 0.000422\n",
      "Epoch 8000/10000, Loss: 0.000415\n",
      "Epoch 8100/10000, Loss: 0.000409\n",
      "Epoch 8200/10000, Loss: 0.000402\n",
      "Epoch 8300/10000, Loss: 0.000396\n",
      "Epoch 8400/10000, Loss: 0.000390\n",
      "Epoch 8500/10000, Loss: 0.000384\n",
      "Epoch 8600/10000, Loss: 0.000378\n",
      "Epoch 8700/10000, Loss: 0.000373\n",
      "Epoch 8800/10000, Loss: 0.000367\n",
      "Epoch 8900/10000, Loss: 0.000362\n",
      "Epoch 9000/10000, Loss: 0.000357\n",
      "Epoch 9100/10000, Loss: 0.000352\n",
      "Epoch 9200/10000, Loss: 0.000347\n",
      "Epoch 9300/10000, Loss: 0.000343\n",
      "Epoch 9400/10000, Loss: 0.000338\n",
      "Epoch 9500/10000, Loss: 0.000334\n",
      "Epoch 9600/10000, Loss: 0.000329\n",
      "Epoch 9700/10000, Loss: 0.000325\n",
      "Epoch 9800/10000, Loss: 0.000321\n",
      "Epoch 9900/10000, Loss: 0.000317\n",
      "Epoch 10000/10000, Loss: 0.000313\n",
      "Training completed! Final Loss: 0.000313\n"
     ]
    }
   ],
   "source": [
    "optimizer = SGD(learning_rate=0.1)\n",
    "optimizer.register_layers(model.layers)\n",
    "history = model.fit(X, Y, epochs=10000, optimizer=optimizer, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcf7e9",
   "metadata": {},
   "source": [
    "### 3.5 Loss Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62537f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4239f74",
   "metadata": {},
   "source": [
    "### 3.6 Model Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "229c6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)\n",
    "classes = model.binary_classify(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e73a8d7",
   "metadata": {},
   "source": [
    "### 3.7 Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e16f77a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True labels:\n",
      "[[0. 1. 1. 0.]]\n",
      "\n",
      "Predicted probabilities:\n",
      "[[0.02409498 0.96846414 0.96574186 0.02473156]]\n",
      "\n",
      "Predicted classes:\n",
      "[[0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrue labels:\")\n",
    "print(Y.T)\n",
    "print(\"\\nPredicted probabilities:\")\n",
    "print(predictions.T)\n",
    "print(\"\\nPredicted classes:\")\n",
    "print(classes.T) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
